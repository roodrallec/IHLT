{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lab Session 9\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import CFG, ChartParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NP (JJ small) (NNS (NNS cats) (CC and) (NNS mice)))\n",
      "(NP (NP (JJ small) (NNS cats)) (CC and) (NP (NNS mice)))\n"
     ]
    }
   ],
   "source": [
    "# Lectures example\n",
    "tokenized_sent = ['small', 'cats', 'and', 'mice']\n",
    "grammar = CFG.fromstring('''\n",
    "    NP -> NNS | JJ NNS | NP CC NP\n",
    "    NNS -> \"cats\" | \"dogs\" | \"mice\" | NNS CC NNS\n",
    "    JJ -> \"big\" | \"small\"\n",
    "    CC -> \"and\" | \"or\"\n",
    "''')\n",
    "parser = ChartParser(grammar)\n",
    "parse = parser.parse(tokenized_sent)\n",
    "for tree in parse:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VBP play) (PP (IN with) (NP (NNS mice)))))\n"
     ]
    }
   ],
   "source": [
    "# Problem example\n",
    "tokenized_sent = ['lazy', 'cats', 'play', 'with', 'mice']\n",
    "grammar = CFG.fromstring('''\n",
    "    S -> NP VP\n",
    "    NP -> JJ NNS\n",
    "    VP -> VBP PP\n",
    "    JJ -> \"lazy\"\n",
    "    NNS -> \"cats\" \n",
    "    VBP -> \"play\"\n",
    "    PP -> IN NP\n",
    "    IN -> \"with\"\n",
    "    NP -> NNS\n",
    "    NNS -> \"mice\"\n",
    "''')\n",
    "parser = ChartParser(grammar)\n",
    "parse = parser.parse(tokenized_sent)\n",
    "for tree in parse:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['small', 'cats', 'and', 'mice']\n",
      "-------\n",
      "(S (NP (JJ small) (NNS (NNS cats) (CC and) (NNS mice))))\n",
      "-------\n",
      "(S (NP (NP (JJ small) (NNS cats)) (CC and) (NP (NNS mice))))\n",
      "##############\n",
      "['lazy', 'cats', 'play', 'with', 'mice']\n",
      "-------\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VBP play) (PP (IN with) (NP (NNS mice)))))\n",
      "##############\n"
     ]
    }
   ],
   "source": [
    "# Joint grammar example\n",
    "# Expand the grammar in the example of non-probabilistic chart parsers\n",
    "# in order to subsume the sentence:\n",
    "grammar = CFG.fromstring('''\n",
    "    S -> NP VP | NP\n",
    "    VP -> VBP PP\n",
    "    JJ -> \"lazy\" \n",
    "    VBP -> \"play\"\n",
    "    PP -> IN NP\n",
    "    IN -> \"with\"\n",
    "    NP -> NNS | JJ NNS | NP CC NP\n",
    "    NNS -> \"cats\" | \"dogs\" | \"mice\" | NNS CC NNS\n",
    "    JJ -> \"big\" | \"small\"\n",
    "    CC -> \"and\" | \"or\"\n",
    "''')\n",
    "parser = ChartParser(grammar)\n",
    "parse = parser.parse(['small', 'cats', 'and', 'mice'])\n",
    "print(['small', 'cats', 'and', 'mice'])\n",
    "for tree in parse:\n",
    "    print('-------')\n",
    "    print(tree)\n",
    "print('##############')\n",
    "parse = parser.parse(['lazy', 'cats', 'play', 'with', 'mice'])\n",
    "print(['lazy', 'cats', 'play', 'with', 'mice'])\n",
    "for tree in parse:\n",
    "    print('-------')\n",
    "    print(tree)\n",
    "print('##############')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "['lazy', 'cats', 'play', 'with', 'mice']\n",
      "-------\n",
      "Resulting tree:\n",
      "-------\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VBP play) (PP (IN with) (NP (NNS mice)))))\n",
      "##############\n",
      "Number of edges: 52\n",
      "-------\n",
      "Resulting tree with edges:\n",
      "-------\n",
      "[0:1] 'lazy'\n",
      "[1:2] 'cats'\n",
      "[2:3] 'play'\n",
      "[3:4] 'with'\n",
      "[4:5] 'mice'\n",
      "[0:0] JJ -> * 'lazy'\n",
      "[0:1] JJ -> 'lazy' *\n",
      "[0:0] NP -> * JJ NNS\n",
      "[0:1] NP -> JJ * NNS\n",
      "[1:1] NNS -> * 'cats'\n",
      "[1:2] NNS -> 'cats' *\n",
      "[1:1] NP -> * NNS\n",
      "[1:1] NNS -> * NNS CC NNS\n",
      "[0:2] NP -> JJ NNS *\n",
      "[1:2] NP -> NNS *\n",
      "[1:2] NNS -> NNS * CC NNS\n",
      "[1:1] S  -> * NP VP\n",
      "[1:1] S  -> * NP\n",
      "[1:1] NP -> * NP CC NP\n",
      "[1:2] S  -> NP * VP\n",
      "[1:2] S  -> NP *\n",
      "[1:2] NP -> NP * CC NP\n",
      "[0:0] S  -> * NP VP\n",
      "[0:0] S  -> * NP\n",
      "[0:0] NP -> * NP CC NP\n",
      "[0:2] S  -> NP * VP\n",
      "[0:2] S  -> NP *\n",
      "[0:2] NP -> NP * CC NP\n",
      "[2:2] VBP -> * 'play'\n",
      "[2:3] VBP -> 'play' *\n",
      "[2:2] VP -> * VBP PP\n",
      "[2:3] VP -> VBP * PP\n",
      "[3:3] IN -> * 'with'\n",
      "[3:4] IN -> 'with' *\n",
      "[3:3] PP -> * IN NP\n",
      "[3:4] PP -> IN * NP\n",
      "[4:4] NNS -> * 'mice'\n",
      "[4:5] NNS -> 'mice' *\n",
      "[4:4] NP -> * NNS\n",
      "[4:4] NNS -> * NNS CC NNS\n",
      "[4:5] NP -> NNS *\n",
      "[4:5] NNS -> NNS * CC NNS\n",
      "[4:4] S  -> * NP VP\n",
      "[4:4] S  -> * NP\n",
      "[4:4] NP -> * NP CC NP\n",
      "[3:5] PP -> IN NP *\n",
      "[4:5] S  -> NP * VP\n",
      "[4:5] S  -> NP *\n",
      "[4:5] NP -> NP * CC NP\n",
      "[2:5] VP -> VBP PP *\n",
      "[1:5] S  -> NP VP *\n",
      "[0:5] S  -> NP VP *\n",
      "##############\n",
      "##############\n",
      "['lazy', 'cats', 'play', 'with', 'mice']\n",
      "-------\n",
      "Resulting tree:\n",
      "-------\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VBP play) (PP (IN with) (NP (NNS mice)))))\n",
      "##############\n",
      "Number of edges: 31\n",
      "-------\n",
      "Resulting tree with edges:\n",
      "-------\n",
      "[0:1] 'lazy'\n",
      "[1:2] 'cats'\n",
      "[2:3] 'play'\n",
      "[3:4] 'with'\n",
      "[4:5] 'mice'\n",
      "[0:1] JJ -> 'lazy' *\n",
      "[0:1] NP -> JJ * NNS\n",
      "[1:2] NNS -> 'cats' *\n",
      "[1:2] NP -> NNS *\n",
      "[1:2] NNS -> NNS * CC NNS\n",
      "[0:2] NP -> JJ NNS *\n",
      "[0:2] S  -> NP * VP\n",
      "[0:2] S  -> NP *\n",
      "[0:2] NP -> NP * CC NP\n",
      "[1:2] S  -> NP * VP\n",
      "[1:2] S  -> NP *\n",
      "[1:2] NP -> NP * CC NP\n",
      "[2:3] VBP -> 'play' *\n",
      "[2:3] VP -> VBP * PP\n",
      "[3:4] IN -> 'with' *\n",
      "[3:4] PP -> IN * NP\n",
      "[4:5] NNS -> 'mice' *\n",
      "[4:5] NP -> NNS *\n",
      "[4:5] NNS -> NNS * CC NNS\n",
      "[4:5] S  -> NP * VP\n",
      "[4:5] S  -> NP *\n",
      "[4:5] NP -> NP * CC NP\n",
      "[3:5] PP -> IN NP *\n",
      "[2:5] VP -> VBP PP *\n",
      "[0:5] S  -> NP VP *\n",
      "[1:5] S  -> NP VP *\n",
      "##############\n",
      "##############\n",
      "['lazy', 'cats', 'play', 'with', 'mice']\n",
      "-------\n",
      "Resulting tree:\n",
      "-------\n",
      "(S\n",
      "  (NP (JJ lazy) (NNS cats))\n",
      "  (VP (VBP play) (PP (IN with) (NP (NNS mice)))))\n",
      "##############\n",
      "Number of edges: 25\n",
      "-------\n",
      "Resulting tree with edges:\n",
      "-------\n",
      "[0:1] 'lazy'\n",
      "[1:2] 'cats'\n",
      "[2:3] 'play'\n",
      "[3:4] 'with'\n",
      "[4:5] 'mice'\n",
      "[0:1] JJ -> 'lazy' *\n",
      "[0:1] NP -> JJ * NNS\n",
      "[1:2] NNS -> 'cats' *\n",
      "[1:2] NP -> NNS *\n",
      "[0:2] NP -> JJ NNS *\n",
      "[0:2] S  -> NP * VP\n",
      "[0:2] S  -> NP *\n",
      "[1:2] S  -> NP * VP\n",
      "[1:2] S  -> NP *\n",
      "[2:3] VBP -> 'play' *\n",
      "[2:3] VP -> VBP * PP\n",
      "[3:4] IN -> 'with' *\n",
      "[3:4] PP -> IN * NP\n",
      "[4:5] NNS -> 'mice' *\n",
      "[4:5] NP -> NNS *\n",
      "[4:5] S  -> NP *\n",
      "[3:5] PP -> IN NP *\n",
      "[2:5] VP -> VBP PP *\n",
      "[0:5] S  -> NP VP *\n",
      "[1:5] S  -> NP VP *\n",
      "##############\n"
     ]
    }
   ],
   "source": [
    "# Perform the constituency parsing using a \n",
    "# BottomUpChartParser, BottomUpLeftCornerChartParser & LeftCornerChartParser\n",
    "# For each one of them, provide the resulting tree, the\n",
    "# number of edges and the list of explored edges.\n",
    "\n",
    "def parse(parser, tokenized_sent):\n",
    "    print('##############')\n",
    "    parse = parser.parse(tokenized_sent)\n",
    "    print(tokenized_sent)\n",
    "    print('-------')\n",
    "    print('Resulting tree:')\n",
    "    for tree in parse:\n",
    "        print('-------')\n",
    "        print(tree)\n",
    "    print('##############')\n",
    "    parse = parser.chart_parse(tokenized_sent)\n",
    "    print('Number of edges:', parse.num_edges())\n",
    "    print('-------')\n",
    "    print('Resulting tree with edges:')\n",
    "    print('-------')\n",
    "    for tree in parse:\n",
    "        print(tree)\n",
    "    print('##############')\n",
    "    return \n",
    "    \n",
    "from nltk.parse.chart import BottomUpChartParser\n",
    "parse(BottomUpChartParser(grammar), tokenized_sent)\n",
    "from nltk.parse.chart import BottomUpLeftCornerChartParser\n",
    "parse(BottomUpLeftCornerChartParser(grammar), tokenized_sent)\n",
    "from nltk.parse.chart import LeftCornerChartParser\n",
    "parse(LeftCornerChartParser(grammar), tokenized_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Which parser is the most efficient for parsing the sentence? Which edges are\n",
    "# filtered out by each parser and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependency parsing. Consider the first three pairs of sentences from the\n",
    "# training set of the evaluation framework of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('jumps', 'VBZ') nsubj ('fox', 'NN')\n",
      "('fox', 'NN') det ('The', 'DT')\n",
      "('fox', 'NN') amod ('quick', 'JJ')\n",
      "('fox', 'NN') amod ('brown', 'JJ')\n",
      "('jumps', 'VBZ') nmod ('dog', 'NN')\n",
      "('dog', 'NN') case ('over', 'IN')\n",
      "('dog', 'NN') det ('the', 'DT')\n",
      "('dog', 'NN') amod ('lazy', 'JJ')\n",
      "('jumps', 'VBZ') punct ('.', '.')\n"
     ]
    }
   ],
   "source": [
    "# Corenlp test\n",
    "from nltk.parse import corenlp\n",
    "parser = corenlp.CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "parse, = parser.raw_parse('The quick brown fox jumps over the lazy dog.')\n",
    "for governor, dep, dependent in parse.triples():\n",
    "    print(governor, dep, dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sent pair\n",
      "['Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence. ', ' Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\\n']\n",
      "\n",
      "Jaccard Distance\n",
      "0.6296296296296297\n",
      "###########################\n",
      "\n",
      "Sent pair\n",
      "[\"Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion. \", \" Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\\n\"]\n",
      "\n",
      "Jaccard Distance\n",
      "0.8387096774193549\n",
      "###########################\n",
      "\n",
      "Sent pair\n",
      "['They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added. ', \" On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\\n\"]\n",
      "\n",
      "Jaccard Distance\n",
      "0.5555555555555556\n",
      "###########################\n"
     ]
    }
   ],
   "source": [
    "# IHLT framework line 1,2,3 analysis\n",
    "from nltk.metrics import jaccard_distance\n",
    "\n",
    "with open('IHLT-eval-framework/train/msr_paraphrase_train_input.txt', 'r') as f:\n",
    "    line1, line2, line3 = next(f), next(f), next(f)\n",
    "sent_pairs = [line1.split('\\t'), line2.split('\\t'), line3.split('\\t')]\n",
    "\n",
    "for pair in sent_pairs:\n",
    "    print('\\nSent pair')\n",
    "    print(pair)\n",
    "    sent_0 = pair[0]\n",
    "    sent_1 = pair[1]\n",
    "    parse_0, = parser.raw_parse(sent_0)\n",
    "    parse_1, = parser.raw_parse(sent_1)\n",
    "    triples_0 = [''.join([str(gov), str(dep), str(depdt)]) for gov, dep, depdt in parse_0.triples()]\n",
    "    triples_1 = [''.join([str(gov), str(dep), str(depdt)]) for gov, dep, depdt in parse_1.triples()]\n",
    "#     print('\\nTriples')\n",
    "#     print(triples_0)\n",
    "#     print('---------------------------')\n",
    "#     print(triples_1)\n",
    "    print('\\nJaccard Distance')\n",
    "    print(jaccard_distance(set(triples_0), set(triples_1)))\n",
    "    print('###########################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sent pair\n",
      "['Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence. ', ' Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence.\\n']\n",
      "\n",
      "Jaccard Distance\n",
      "0.3333333333333333\n",
      "###########################\n",
      "\n",
      "Sent pair\n",
      "[\"Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion. \", \" Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.\\n\"]\n",
      "\n",
      "Jaccard Distance\n",
      "0.5135135135135135\n",
      "###########################\n",
      "\n",
      "Sent pair\n",
      "['They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added. ', \" On June 10, the ship's owners had published an advertisement on the Internet, offering the explosives for sale.\\n\"]\n",
      "\n",
      "Jaccard Distance\n",
      "0.3235294117647059\n",
      "###########################\n"
     ]
    }
   ],
   "source": [
    "# IHLT framework line 1,2,3 analysis\n",
    "# Flattenned array\n",
    "from nltk.metrics import jaccard_distance\n",
    "\n",
    "with open('IHLT-eval-framework/train/msr_paraphrase_train_input.txt', 'r') as f:\n",
    "    line1, line2, line3 = next(f), next(f), next(f)\n",
    "sent_pairs = [line1.split('\\t'), line2.split('\\t'), line3.split('\\t')]\n",
    "\n",
    "for pair in sent_pairs:\n",
    "    print('\\nSent pair')\n",
    "    print(pair)\n",
    "    sent_0 = pair[0]\n",
    "    sent_1 = pair[1]\n",
    "    parse_0, = parser.raw_parse(sent_0)\n",
    "    parse_1, = parser.raw_parse(sent_1)\n",
    "    triples_0 = []\n",
    "    triples_1 = []\n",
    "    \n",
    "    for gov, dep, depdt in parse_0.triples():\n",
    "        triples_0.append(str(gov))\n",
    "        triples_0.append(str(dep))\n",
    "        triples_0.append(str(depdt))\n",
    "\n",
    "    for gov, dep, depdt in parse_1.triples():\n",
    "        triples_1.append(str(gov))\n",
    "        triples_1.append(str(dep))\n",
    "        triples_1.append(str(depdt))\n",
    "    \n",
    "#     print('\\nTriples')\n",
    "#     print(triples_0)\n",
    "#     print('---------------------------')\n",
    "#     print(triples_1)\n",
    "    print('\\nJaccard Distance')\n",
    "    print(jaccard_distance(set(triples_0), set(triples_1)))\n",
    "    print('###########################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
